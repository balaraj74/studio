
'use server';

/**
 * @fileOverview An AI-powered live advisor for farmers.
 *
 * - liveFarmAdvisor - A function that handles real-time visual analysis and voice queries.
 * - LiveFarmAdvisorInput - The input type for the function.
 * - LiveFarmAdvisorOutput - The return type for the function.
 */

import { ai } from '@/ai/genkit';
import { z } from 'zod';
import { googleAI } from '@genkit-ai/googleai';


const LiveFarmAdvisorInputSchema = z.object({
  videoFrameUri: z.string().describe("A single frame from the live video, as a data URI. Format: 'data:image/jpeg;base64,<encoded_data>'."),
  farmerQuery: z.string().describe("The transcribed voice query from the farmer."),
  language: z.string().describe("The language for the response, e.g., 'English', 'Kannada'."),
});
export type LiveFarmAdvisorInput = z.infer<typeof LiveFarmAdvisorInputSchema>;

const LiveFarmAdvisorOutputSchema = z.object({
  visualAnalysis: z.string().describe("A brief, one-sentence summary of what is seen in the video frame (e.g., 'A tomato plant with yellowing leaves.')."),
  responseToQuery: z.string().describe("A direct, helpful, and empathetic answer to the farmer's specific query, generated in the requested language."),
  proactiveAlert: z.string().describe("A proactive alert or suggestion based on the visual analysis, such as a potential disease risk or a farming tip. 'None' if no immediate alert is necessary."),
});
export type LiveFarmAdvisorOutput = z.infer<typeof LiveFarmAdvisorOutputSchema>;

export async function liveFarmAdvisor(input: LiveFarmAdvisorInput): Promise<LiveFarmAdvisorOutput> {
  return liveFarmAdvisorFlow(input);
}


const liveFarmAdvisorFlow = ai.defineFlow(
  {
    name: 'liveFarmAdvisorFlow',
    inputSchema: LiveFarmAdvisorInputSchema,
    outputSchema: LiveFarmAdvisorOutputSchema,
  },
  async (input) => {
    try {
      const promptText = `You are a Gemini-powered virtual agronomist conducting a live video call with a farmer. Your tone should be empathetic, knowledgeable, and helpful. The entire response must be in ${input.language}.

      You are analyzing a single frame from their live video feed and responding to their voice query.

      1.  **Analyze the Visuals**: First, briefly describe what you see in the image. This is your visual analysis.
      2.  **Answer the Query**: Directly answer the farmer's question based on both the visual evidence and your agricultural knowledge.
      3.  **Provide Proactive Advice**: Based on what you see, provide a proactive alert or a helpful tip. If you see signs of a potential issue (like pests or disease), mention it here. If everything looks fine, you can say 'None' or offer a general tip.

      **Farmer's Query:** "${input.farmerQuery}"

      Generate a structured response based on these instructions.
      `;
      
      const promptPayload = [
        { media: { url: input.videoFrameUri } },
        { text: promptText },
      ];

      const { output } = await ai.generate({
          prompt: promptPayload, 
          model: googleAI.model('gemini-1.5-flash'),
          output: { schema: LiveFarmAdvisorOutputSchema }
      });
      
      if (!output) {
        throw new Error("No output was generated by the AI model.");
      }
      return output;

    } catch (error) {
       console.error("Error in liveFarmAdvisorFlow:", error);
       const errorMessage = error instanceof Error ? error.message : "An unknown error occurred during the analysis.";
       throw new Error(`The AI advisor could not process the request. Details: ${errorMessage}`);
    }
  }
);
